# RUKA: Rethinking the Design of Humanoid Hands with Learning

**Authors**: Anya Zorin, Irmak Guzey, Billy Yan, Aadhithya Iyer, Lisa Kondrich, Nikhil X. Bhattasali, Lerrel Pinto

**Published**: 2025-04-17

**arXiv**: [2504.13165](https://arxiv.org/abs/2504.13165)

**GitHub**: [https://github.com/ruka-hand/RUKA](https://github.com/ruka-hand/RUKA) ‚≠ê 153 üîÄ 20

**Twitter**: [Announcement Tweet](https://x.com/irmakkguzey/status/1913276064287305730) ‚ù§Ô∏è 445 üîÑ 100 üëÅÔ∏è 109,358

**Relevance Score**: 40.8/100

**Domains**: dexterous, manipulation

**Tags**: `dexterous`, `hand`, `hardware`, `Stanford`

---

## Summary

Dexterous manipulation is a fundamental capability for robotic systems, yet progress has been limited by hardware trade-offs between precision, compactness, strength, and affordability. Existing control methods impose compromises on hand designs and applications. However, learning-based approaches present opportunities to rethink these trade-offs, particularly to address challenges with tendon-driven actuation and low-cost materials. This work presents RUKA, a tendon-driven humanoid hand that is compact, affordable, and capable. Made from 3D-printed parts and off-the-shelf components, RUKA has 5 fingers with 15 underactuated degrees of freedom enabling diverse human-like grasps. Its tendon-driven actuation allows powerful grasping in a compact, human-sized form factor. To address control challenges, we learn joint-to-actuator and fingertip-to-actuator models from motion-capture data collected by the MANUS glove, leveraging the hand's morphological accuracy. Extensive evaluations demonstrate RUKA's superior reachability, durability, and strength compared to other robotic hands. Teleoperation tasks further showcase RUKA's dexterous movements. The open-source design and assembly instructions of RUKA, code, and data are available at https://ruka-hand.github.io/.
