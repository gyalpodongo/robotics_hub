# AHA: A Vision-Language-Model for Detecting and Reasoning Over Failures in Robotic Manipulation

**Authors**: Jiafei Duan, Wilbert Pumacay, Nishanth Kumar, Yi Ru Wang, Shulin Tian, Wentao Yuan, Ranjay Krishna, Dieter Fox, Ajay Mandlekar, Yijie Guo

**Published**: 2024-10-01

**arXiv**: [2410.00371](https://arxiv.org/abs/2410.00371)

**GitHub**: [https://github.com/NVlabs/AHA](https://github.com/NVlabs/AHA) ‚≠ê 49 üîÄ 3

**Twitter**: [Announcement Tweet](https://x.com/DJiafei/status/1838562171460161619) ‚ù§Ô∏è 201 üîÑ 43 üëÅÔ∏è 48,462

**Relevance Score**: 29.5/100

**Domains**: vla

**Tags**: `VLA`, `failure-detection`, `reasoning`

---

## Summary

Robotic manipulation in open-world settings requires not only task execution but also the ability to detect and learn from failures. While recent advances in vision-language models (VLMs) and large language models (LLMs) have improved robots' spatial reasoning and problem-solving abilities, they still struggle with failure recognition, limiting their real-world applicability. We introduce AHA, an open-source VLM designed to detect and reason about failures in robotic manipulation using natural language. By framing failure detection as a free-form reasoning task, AHA identifies failures and provides detailed, adaptable explanations across different robots, tasks, and environments. We fine-tuned AHA using FailGen, a scalable framework that generates the first large-scale dataset of robotic failure trajectories, the AHA dataset. FailGen achieves this by procedurally perturbing successful demonstrations from simulation. Despite being trained solely on the AHA dataset, AHA generalizes effectively to real-world failure datasets, robotic systems, and unseen tasks. It surpasses the second-best model (GPT-4o in-context learning) by 10.3% and exceeds the average performance of six compared models including five state-of-the-art VLMs by 35.3% across multiple metrics and datasets. We integrate AHA into three manipulation frameworks that utilize LLMs/VLMs for reinforcement learning, task and motion planning, and zero-shot trajectory generation. AHA's failure feedback enhances these policies' performances by refining dense reward functions, optimizing task planning, and improving sub-task verification, boosting task success rates by an average of 21.4% across all three tasks compared to GPT-4 models.
