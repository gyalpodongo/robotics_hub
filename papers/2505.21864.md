# DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation

**Authors**: Mengda Xu, Han Zhang, Yifan Hou, Zhenjia Xu, Linxi Fan, Manuela Veloso, Shuran Song

**Published**: 2025-05-28

**arXiv**: [2505.21864](https://arxiv.org/abs/2505.21864)

**GitHub**: [https://github.com/real-stanford/DexUMI](https://github.com/real-stanford/DexUMI) ‚≠ê 145 üîÄ 13

**Citations**: [10](https://www.semanticscholar.org/paper/22550cdfb498e0890e75e504d8ab5dd5e0ca8729)

**Relevance Score**: 43.2/100

**Domains**: dexterous, data_collection

**Tags**: `dexterous`, `teleoperation`, `hand`, `Stanford`

---

## Summary

We present DexUMI - a data collection and policy learning framework that uses the human hand as the natural interface to transfer dexterous manipulation skills to various robot hands. DexUMI includes hardware and software adaptations to minimize the embodiment gap between the human hand and various robot hands. The hardware adaptation bridges the kinematics gap using a wearable hand exoskeleton. It allows direct haptic feedback in manipulation data collection and adapts human motion to feasible robot hand motion. The software adaptation bridges the visual gap by replacing the human hand in video data with high-fidelity robot hand inpainting. We demonstrate DexUMI's capabilities through comprehensive real-world experiments on two different dexterous robot hand hardware platforms, achieving an average task success rate of 86%.
