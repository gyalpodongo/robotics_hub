# Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots

arXiv: [2402.10329](https://arxiv.org/abs/2402.10329) | Published: Feb 15, 2024

**Authors**: Cheng Chi, Zhenjia Xu, Chuer Pan, Eric Cousineau, Benjamin Burchfiel, Siyuan Feng, Russ Tedrake, Shuran Song

---

## ğŸ“Š Metrics Summary

| ğŸ“„ PDF | â­ Stars | ğŸ”€ Forks | ğŸ“š Citations | ğŸ“ˆ Influential | â¤ï¸ Likes | ğŸ” Retweets | ğŸ‘ï¸ Views | ğŸ”§ Issues | ğŸ“ PRs | ğŸ¯ Score |
|---------|---------|---------|-------------|---------------|----------|------------|----------|----------|---------|----------|
| [2402.10329](https://arxiv.org/abs/2402.10329) | 1.1k | 202 | â€” | â€” | 1.8k | 370 | 432.2k | 63 | 1 | 30.0 |

**Links**: [GitHub](https://github.com/real-stanford/universal_manipulation_interface) â€¢ [Twitter](https://x.com/chichengcc/status/1758539728444629158) â€¢ [Semantic Scholar](#)

---

## ğŸ“ Abstract

We present Universal Manipulation Interface (UMI) -- a data collection and policy learning framework that allows direct skill transfer from in-the-wild human demonstrations to deployable robot policies. UMI employs hand-held grippers coupled with careful interface design to enable portable, low-cost, and information-rich data collection for challenging bimanual and dynamic manipulation demonstrations. To facilitate deployable policy learning, UMI incorporates a carefully designed policy interface with inference-time latency matching and a relative-trajectory action representation. The resulting learned policies are hardware-agnostic and deployable across multiple robot platforms. Equipped with these features, UMI framework unlocks new robot manipulation capabilities, allowing zero-shot generalizable dynamic, bimanual, precise, and long-horizon behaviors, by only changing the training data for each task. We demonstrate UMI's versatility and efficacy with comprehensive real-world experiments, where policies learned via UMI zero-shot generalize to novel environments and objects when trained on diverse human demonstrations. UMI's hardware and software system is open-sourced at https://umi-gripper.github.io.

---

## ğŸ› Latest Issues

| # | Issue | Created |
|---|-------|----------|
| [#93](https://github.com/real-stanford/universal_manipulation_interface/issues/93) | What is Spacemouse in this project for? | Nov 06, 2025 |
| [#92](https://github.com/real-stanford/universal_manipulation_interface/issues/92) | UMI ON JAKA:  JAKA Robot Arm Successfully Reproduces UMI Project, Achieving Cross-Platform Validation | Oct 30, 2025 |
| [#91](https://github.com/real-stanford/universal_manipulation_interface/issues/91) | UMI Compatible Fingertip STL for Robotiq 2F-85/140 | Oct 21, 2025 |

[View all issues â†’](https://github.com/real-stanford/universal_manipulation_interface/issues)

---

## ğŸ”„ Recent Activity

| Type | Activity | Author | Date |
|------|----------|--------|------|
| ğŸ“ Commit | [`8ea6ba7`](https://github.com/real-stanford/universal_manipulation_interface/commit/8ea6ba767a981be8d7b3be84f1bdbd74dbf2c2ed) Add gif for ARX arm | Yihuai Gao | Dec 18, 2024 |
| ğŸ“ Commit | [`204668f`](https://github.com/real-stanford/universal_manipulation_interface/commit/204668f044a77fc90036397233cf653d8d57ca4e) Update README.md | Yihuai Gao | Dec 18, 2024 |
| ğŸ“ Commit | [`298776c`](https://github.com/real-stanford/universal_manipulation_interface/commit/298776ce251f33b6b3185a98d6e7d1f9ad49168b) add franka instruction | Zhenjia Xu | Apr 03, 2024 |
| ğŸ“ Commit | [`5e58e6f`](https://github.com/real-stanford/universal_manipulation_interface/commit/5e58e6f7175b21355f61c1dcb69cd5081122d74a) fix | Cheng Chi | Mar 19, 2024 |
| ğŸ“ Commit | [`d99eddb`](https://github.com/real-stanford/universal_manipulation_interface/commit/d99eddb230ee43f12939afa1b3dc6daee53ba790) fix | Cheng Chi | Mar 19, 2024 |

[View all activity â†’](https://github.com/real-stanford/universal_manipulation_interface/commits)

---

**Last Updated**: 2025-11-14 09:01:49 UTC
