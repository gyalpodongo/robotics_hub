# AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers

**Authors**: Yongchao Chen, Jacob Arkin, Charles Dawson, Yang Zhang, Nicholas Roy, Chuchu Fan

**Published**: 2023-06-10

**arXiv**: [2306.06531](https://arxiv.org/abs/2306.06531)


**Citations**: [143](https://www.semanticscholar.org/paper/dc135dabef805c7271f53ec4b212bdf8996cfd9d) (ðŸ“ˆ 10 influential)

**Relevance Score**: 37.1/100

**Domains**: hri_planning

**Tags**: `LLM`, `TAMP`, `planning`, `AutoTAMP`

---

## Summary

For effective human-robot interaction, robots need to understand, plan, and execute complex, long-horizon tasks described by natural language. Recent advances in large language models (LLMs) have shown promise for translating natural language into robot action sequences for complex tasks. However, existing approaches either translate the natural language directly into robot trajectories or factor the inference process by decomposing language into task sub-goals and relying on a motion planner to execute each sub-goal. When complex environmental and temporal constraints are involved, inference over planning tasks must be performed jointly with motion plans using traditional task-and-motion planning (TAMP) algorithms, making factorization into subgoals untenable. Rather than using LLMs to directly plan task sub-goals, we instead perform few-shot translation from natural language task descriptions to an intermediate task representation that can then be consumed by a TAMP algorithm to jointly solve the task and motion plan. To improve translation, we automatically detect and correct both syntactic and semantic errors via autoregressive re-prompting, resulting in significant improvements in task completion. We show that our approach outperforms several methods using LLMs as planners in complex task domains. See our project website https://yongchao98.github.io/MIT-REALM-AutoTAMP/ for prompts, videos, and code.
