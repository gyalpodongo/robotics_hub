# Consistency Policy: Accelerated Visuomotor Policies via Consistency Distillation

**Authors**: Aaditya Prasad, Kevin Lin, Jimmy Wu, Linqi Zhou, Jeannette Bohg

**Published**: 2024-05-13

**arXiv**: [2405.07503](https://arxiv.org/abs/2405.07503)

**GitHub**: [https://github.com/Aaditya-Prasad/Consistency-Policy](https://github.com/Aaditya-Prasad/Consistency-Policy) ‚≠ê 189 üîÄ 14

**Twitter**: [Announcement Tweet](https://x.com/_Aaditya_Prasad/status/1790501613653917782) ‚ù§Ô∏è 291 üîÑ 61 üëÅÔ∏è 78,723

**Citations**: [89](https://www.semanticscholar.org/paper/289906e335e367d363bc2e99d1c04037da7afbf2) (üìà 11 influential)

**Relevance Score**: 23.9/100

**Domains**: policy_methods

**Tags**: `diffusion`, `policy`, `consistency`, `real-time`

---

## Summary

Many robotic systems, such as mobile manipulators or quadrotors, cannot be equipped with high-end GPUs due to space, weight, and power constraints. These constraints prevent these systems from leveraging recent developments in visuomotor policy architectures that require high-end GPUs to achieve fast policy inference. In this paper, we propose Consistency Policy, a faster and similarly powerful alternative to Diffusion Policy for learning visuomotor robot control. By virtue of its fast inference speed, Consistency Policy can enable low latency decision making in resource-constrained robotic setups. A Consistency Policy is distilled from a pretrained Diffusion Policy by enforcing self-consistency along the Diffusion Policy's learned trajectories. We compare Consistency Policy with Diffusion Policy and other related speed-up methods across 6 simulation tasks as well as three real-world tasks where we demonstrate inference on a laptop GPU. For all these tasks, Consistency Policy speeds up inference by an order of magnitude compared to the fastest alternative method and maintains competitive success rates. We also show that the Conistency Policy training procedure is robust to the pretrained Diffusion Policy's quality, a useful result that helps practioners avoid extensive testing of the pretrained model. Key design decisions that enabled this performance are the choice of consistency objective, reduced initial sample variance, and the choice of preset chaining steps.
