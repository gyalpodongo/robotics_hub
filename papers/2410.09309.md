# Adaptive Compliance Policy: Learning Approximate Compliance for Diffusion Guided Control

**Authors**: Yifan Hou, Zeyi Liu, Cheng Chi, Eric Cousineau, Naveen Kuppuswamy, Siyuan Feng, Benjamin Burchfiel, Shuran Song

**Published**: 2024-10-12

**arXiv**: [2410.09309](https://arxiv.org/abs/2410.09309)

**GitHub**: [https://github.com/yifan-hou/adaptive_compliance_policy](https://github.com/yifan-hou/adaptive_compliance_policy) ‚≠ê 92 üîÄ 8

**Relevance Score**: 43.9/100

**Domains**: manipulation

**Tags**: `compliance`, `diffusion`, `contact-rich`, `Stanford`

---

## Summary

Compliance plays a crucial role in manipulation, as it balances between the concurrent control of position and force under uncertainties. Yet compliance is often overlooked by today's visuomotor policies that solely focus on position control. This paper introduces Adaptive Compliance Policy (ACP), a novel framework that learns to dynamically adjust system compliance both spatially and temporally for given manipulation tasks from human demonstrations, improving upon previous approaches that rely on pre-selected compliance parameters or assume uniform constant stiffness. However, computing full compliance parameters from human demonstrations is an ill-defined problem. Instead, we estimate an approximate compliance profile with two useful properties: avoiding large contact forces and encouraging accurate tracking. Our approach enables robots to handle complex contact-rich manipulation tasks and achieves over 50\% performance improvement compared to state-of-the-art visuomotor policy methods. For result videos, see https://adaptive-compliance.github.io/
