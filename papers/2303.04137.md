# Diffusion Policy: Visuomotor Policy Learning via Action Diffusion

arXiv: [2303.04137](https://arxiv.org/abs/2303.04137) | Published: Mar 07, 2023

**Authors**: Cheng Chi, Zhenjia Xu, Siyuan Feng, Eric Cousineau, Yilun Du, Benjamin Burchfiel, Russ Tedrake, Shuran Song

---

## ğŸ“Š Metrics Summary

| ğŸ“„ PDF | â­ Stars | ğŸ”€ Forks | ğŸ“š Citations | ğŸ“ˆ Influential | â¤ï¸ Likes | ğŸ” Retweets | ğŸ‘ï¸ Views | ğŸ”§ Issues | ğŸ“ PRs | ğŸ¯ Score |
|---------|---------|---------|-------------|---------------|----------|------------|----------|----------|---------|----------|
| [2303.04137](https://arxiv.org/abs/2303.04137) | 3.3k | 612 | 1.9k | 464 | 534 | 101 | 129.0k | 91 | 6 | 53.8 |

**Links**: [GitHub](https://github.com/real-stanford/diffusion_policy) â€¢ [Twitter](https://x.com/chichengcc/status/1633339455250526213) â€¢ [Semantic Scholar](https://www.semanticscholar.org/paper/bdba3bd30a49ea4c5b20b43dbd8f0eb59e9d80e2)

---

## ğŸ“ Abstract

This paper introduces Diffusion Policy, a new way of generating robot behavior by representing a robot's visuomotor policy as a conditional denoising diffusion process. We benchmark Diffusion Policy across 12 different tasks from 4 different robot manipulation benchmarks and find that it consistently outperforms existing state-of-the-art robot learning methods with an average improvement of 46.9%. Diffusion Policy learns the gradient of the action-distribution score function and iteratively optimizes with respect to this gradient field during inference via a series of stochastic Langevin dynamics steps. We find that the diffusion formulation yields powerful advantages when used for robot policies, including gracefully handling multimodal action distributions, being suitable for high-dimensional action spaces, and exhibiting impressive training stability. To fully unlock the potential of diffusion models for visuomotor policy learning on physical robots, this paper presents a set of key technical contributions including the incorporation of receding horizon control, visual conditioning, and the time-series diffusion transformer. We hope this work will help motivate a new generation of policy learning techniques that are able to leverage the powerful generative modeling capabilities of diffusion models. Code, data, and training details is publicly available diffusion-policy.cs.columbia.edu

---

## ğŸ› Latest Issues

| # | Issue | Created |
|---|-------|----------|
| [#156](https://github.com/real-stanford/diffusion_policy/issues/156) | Diffusion Policy seems to ignore forceâ€“torque (FT) inputs â€” how do I make force matter? | Nov 12, 2025 |
| [#155](https://github.com/real-stanford/diffusion_policy/issues/155) | cannot import name 'DEFAULT_CIPHERS' from 'urllib3.util.ssl_ | Nov 11, 2025 |

[View all issues â†’](https://github.com/real-stanford/diffusion_policy/issues)

---

## ğŸ”„ Recent Activity

| Type | Activity | Author | Date |
|------|----------|--------|------|
| ğŸ“ Commit | [`5ba07ac`](https://github.com/real-stanford/diffusion_policy/commit/5ba07ac6661db573af695b419a7947ecb704690f) Done adapting mujoco image dataset | Yihuai Gao | Dec 24, 2024 |
| ğŸ“ Commit | [`548a52b`](https://github.com/real-stanford/diffusion_policy/commit/548a52bbb105518058e27bf34dcf90bf6f73681a) Merge pull request #27 from pointW/main | Cheng Chi | Oct 27, 2023 |
| ğŸ“ Commit | [`de4384e`](https://github.com/real-stanford/diffusion_policy/commit/de4384e84ad0db128fdcf76e3a2e21a5ec7947da) fix typo in rotation_transformer.py | Dian Wang | Oct 25, 2023 |
| ğŸ“ Commit | [`7dd9dc4`](https://github.com/real-stanford/diffusion_policy/commit/7dd9dc417aa30f4ac0e28c7f3ce791a7f007256a) Merge pull request #21 from columbia-ai-robotics/c... | Cheng Chi | Sep 13, 2023 |
| ğŸ“ Commit | [`5aa9996`](https://github.com/real-stanford/diffusion_policy/commit/5aa9996fdc9cbf1c7567057e94e33f997515bddd) pinned llvm-openmp version to avoid cpu affinity b... | Cheng Chi | Sep 13, 2023 |

[View all activity â†’](https://github.com/real-stanford/diffusion_policy/commits)

---

**Last Updated**: 2025-11-14 09:01:28 UTC
